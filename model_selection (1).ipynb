{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble, tree, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions\n",
    "We are going to need to split our data and define a function to run the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, label, train_size=.8):\n",
    "    \"\"\" \n",
    "    Split processed data into train and test sets. Extract labels. Also stores indexed labels and data in the process.\n",
    "    Data is required to have the label_col column that represents train and test labels.\n",
    "    \"\"\"\n",
    "    # Carve out holdout data\n",
    "    holdout = data.sample(frac=.2)\n",
    "    non_holdout_data = data.drop(holdout.index, axis=0)\n",
    "    holdout_labels = holdout[label] \n",
    "    holdout_data = holdout.drop([label], axis=1)\n",
    "\n",
    "    # split out train and test from non-holdout data\n",
    "    labeled_train_data = non_holdout_data.sample(frac=.8)\n",
    "    labeled_test_data = non_holdout_data.drop(labeled_train_data.index)\n",
    "\n",
    "    train_data = labeled_train_data.drop([label], axis=1).reset_index(drop=True)\n",
    "    train_labels = labeled_train_data[label].reset_index(drop=True)\n",
    "\n",
    "    test_data = labeled_test_data.drop([label], axis=1).reset_index(drop=True)\n",
    "    test_labels = labeled_test_data[label].reset_index(drop=True)\n",
    "\n",
    "    # normalize data\n",
    "    scaler = StandardScaler()\n",
    "    normed_train_data = scaler.fit_transform(train_data)\n",
    "    normed_test_data = scaler.transform(test_data)\n",
    "    normed_holdout_data = scaler.transform(holdout_data)\n",
    "\n",
    "    return normed_train_data, normed_test_data, normed_holdout_data, train_labels, test_labels, holdout_labels\n",
    "\n",
    "        \n",
    "def run_grid(clf, grid, train_data, test_data, train_labels, test_labels, n_jobs=-1, score=\"accuracy\"):\n",
    "    \"\"\" \n",
    "    Runs SKLearn implementation of grid search \n",
    "    clf: un-fit SKLearn classifier\n",
    "    grid: params upon which grid search will run\n",
    "    data: pandas DataFrame of model data, inclusive of label\n",
    "    label: name of column that holds classification labels\n",
    "\n",
    "    returns: Most accurate model\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=grid, n_jobs=n_jobs, scoring=score)\n",
    "    best_clf = grid_search.fit(train_data, train_labels).best_estimator_\n",
    "\n",
    "    # get model predictions and accuracy\n",
    "    preds = best_clf.predict(test_data)\n",
    "    acc = metrics.accuracy_score(preds, test_labels)\n",
    "    print(f\"PREDS: {preds.mean():.2f}\")\n",
    "    acc = metrics.accuracy_score(test_labels, preds)\n",
    "    print(f\"Model Accuracy: {acc*100:.1f}%\")\n",
    "\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split out data and define param lists that we will iterate through when running the grid search.\n",
    "\n",
    "For this exercise, we will use a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "model_data = pd.read_csv(\"C:/Users/lbianculli/equity_analysis/model_data_final.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "train_data, test_data, holdout_data, train_labels, test_labels, holdout_labels = train_test_split(model_data, \"label\")\n",
    "\n",
    "# save data and labels so we are always using/not using the same data!\n",
    "with open(\"C:/Users/lbianculli/dev/us_equities/models/train_data.p\", \"wb\") as f:\n",
    "    pickle.dump([train_data, test_data, holdout_data, train_labels, test_labels, holdout_labels], f)\n",
    "    \n",
    "    \n",
    "# define params to iterate over for search\n",
    "print(f\"Number of features: {train_data.shape[1]}\")\n",
    "\n",
    "# set up grid search for Random Forest Classifier\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [None, 25, 50]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "class_weight = [None, \"balanced\"]\n",
    "\n",
    "rf_grid = { \n",
    "    'max_features': max_features, \n",
    "    'max_depth': max_depth, \n",
    "    'min_samples_split': min_samples_split, \n",
    "    \"class_weight\": class_weight}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS: -0.70\n",
      "Model Accuracy: 86.1%\n"
     ]
    }
   ],
   "source": [
    "# set up classifier and run search\n",
    "rf_clf = ensemble.RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "best_rf = run_grid(rf_clf, rf_grid, train_data=train_data, test_data=test_data, train_labels=train_labels, \\\n",
    "                         test_labels=test_labels, n_jobs=6, score=\"accuracy\")\n",
    "\n",
    "# save model for evaluation\n",
    "with open(\"C:/Users/lbianculli/dev/us_equities/models/sk_random_forest_final.f\", \"wb\") as f:\n",
    "    pickle.dump(best_rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have our classifier, we move onto model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
